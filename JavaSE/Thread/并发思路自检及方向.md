## 并发编程的核心问题

并发编程领域可以分为三个核心问题：分工、同步和互斥

### 1、分工

例如一个工作里面有很多的 task，这些 task 在并发领域中决定了并发程序的性能。在 Java SDK 并发包中的 ``Executor``、``Fork/Join``、``Future`` 本质都是一种分工方法。除此之外，还有一些设计模式，基本上都是和分工相关的，例如``生产者-消费者``、``Thread-Per-Message``、``Worker Thread`` 模式等都是用来指导你如何分工的。

------

### 2、同步

分工好了之后，就开始任务的具体执行。在项目中，任务是有以来的。一个任务结束后，依赖它的后续任务就可以开始了



并发领域同步，就是指线程之间的协作，本质和显示生活的协作没有区别。重要的是**线程执行完了一个任务，如何通知执行后续任务的线程开始进行**

Java SDK 并发包中的 ``Executor``、``Fork/Join``、``Future`` 本质上都是分工，也与协作密切相关。例如，使用 Future 可以发起一个异步调用，当主线程通过 get() 方法取结果时，主线程就会等待，当异步执行的结果返回时，get() 方法就会自动返回。主线程和异步线程之间的协作，Future 工具类已经帮我们解决大部分功能。除此之外还有 ``CountDownLatch``、``CyclicBarrier``、``Phaser``、``Exchanger`` 也都是解决线程间协作的问题。



我们平时遇到的问题，都可以抽象出来一个基本模型：

- 当条件不满足，线程需要等待
- 当某个条件满足，线程需要被唤醒执行

在生产者-消费者模型中，也有类似的描述，"当队列满时，生产者线程等待。当队列不满时，生产者线程需要被唤醒执行；当队列空时，消费者线程等待，当队列不空时，消费者线程需要被唤醒执行"

------

### 3、互斥

分工、同步强调的是性能，但并发领域中有一部分是关于正确性的，用专业术语就是**线程安全**。并发程序中，当多个线程访问同一个共享变量的时候，结果是不确定的。不确定意味着可能正确可能错误，事先是不知道的。而导致问题的源头就是可见性、原子性和有序性。



为了解决上述的问题，Java 语言引入了内存模型，内存模型提供了一系列的规则，利用这些规则，可以解决有限数量的问题，但解决的核心依旧是互斥。



**所谓互斥，就是在同一时刻，只允许有一个线程访问共享变量**

实现互斥的核心技术就是锁，Java 语言里 synchronized，SDK 中的各种 Lock 都可以解决互斥问题，但是也带来了性能问题。我们的目标就是，在保障安全性的同时也尽量提高性能。

针对场景进行优化，Java SDK 中提供的 ReadWriteLock、StampedLock 就可以优化读多写少场景下的锁的性能。还可以使用无锁的数据结构，例如 SDK 提供的原子类都是基于无锁技术实现的。

除此之外还有一些其他的方案，原理是不共享变量或者变量只允许读。这方面提供了 ThreadLocal 和 final 关键字，还有一种 [Copy-on-write](<https://github.com/DraperHXY/Notes/blob/master/JavaSE/CopyOnWrite.md>) 模式



除了锁的性能之外，还需要注意死锁的问题。按照前面我们大部分遇到的线程问题的模型：

* 当条件不满足，线程等待
* 当条件被满足，线程被唤醒

再结合**分工**-**同步**-**互斥**来看，就可以写出一个死锁，例如[两个 Object 实现一个死锁](<https://github.com/DraperHXY/JavaLearning/blob/master/src/main/java/com/draper/thread/DeadLock.java>)

有两个对象，分别持有让对方等待的资源，但是条件没有被满足，都在等对方释放资源，陷入饿死



## 那些年导致我们并发程序出现 bug 的源头

随着 CPU，内存，I/O的不断迭代，设备的处理速度越来越快。但是核心矛盾依然存在，即这些设备的处理速度的差异。为了利用 CPU 的高性能，平衡这些设备的差异，所以计算机体系结构、操作系统、编译程序都做了贡献：

- CPU 增加了缓存，用于均衡与内存的速度差异
- OS 增加了进程，线程，以分时复用 CPU，从而均衡 CPU 与 I/O 的速度差异
- 编译程序又花了指令执行次序，从而使得缓存可以更合理的得到运用



### **1、Bug 的源头之一 ：可见性**

在单核处理时代，所有的线程在一个 CPU 上执行，CPU 和 内存的数据一致性比较容易解决。因为所有的操作都是在对一个 CPU 的缓存进行操作，一个线程对于 CPU 缓存的操作，对另外一个线程是可见的，但是在多核处理器中，每个 CPU 都有自己独立的 缓存，而属于不同 CPU 的线程来说，对同一变量的操作，不同线程之间就不具备可见性了。



### **2、Bug 的源头之一：线程切换带来的原子性**

```java
count += 1;
```

在这个指令中，至少需要三条 CPU 指令

- 把 count 从内存中加载到 CPU 的寄存器中
- 在寄存器中执行 +1 操作
- 将结果写入内存(缓存机制指的是 CPU 的缓存而并非内存)

**在潜意识中，这条 count += 1看起来很像是真的符合原子性。我们把一个或多个在 CPU 执行过程中不混中断的特性成为原子性。**

CPU 保证的原子性操作是 CPU 指令级别的，而不是高级语言的操作符。所以很多时候，我们需要的是在高级语言层面保证操作的原子性



### **3、Bug 的源头之三：编译优化带来的有序性问题**

编译器为了优化性能会进行一个指令重排序

例如在我这篇[如何正确地写出单例模式](<https://github.com/DraperHXY/Notes/blob/master/JavaSE/%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%9C%B0%E5%86%99%E5%87%BA%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F.md>)中在对普通的双简锁实现单例模式容易忽略的问题，使用 volatile 产生内存屏障，避免编译器进行指令优化。



总而言之，就是**缓存**带来了可见性问题，**线程切换**带来原子性问题，**编译优化**带来了有序性问题



基本上并发编程出现的问题主要围绕着以上三点