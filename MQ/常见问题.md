## Q: 如何保证消息不被重复消费（如何保证消息消费的幂等性）？

> 

> kafka 消息 offset 批量提交，导致重复消费，从而导致业务在 DB 中重复插入两次

 A: 使用一套幂等性保障机制

### CASE1

可以往内存 Set 存放 id = 1 这样的数据，如果有重复的数据，去内存 Set 里检查，这个消息是否存在：有意味着已经被处理了，丢弃消息。如果没有，再进行操作

### CASE2

基于数据库的唯一键，确保不会处理重复的数据，导致脏数据。



## Q: 如何保证消息的可靠性传输（如何处理消息丢失问题）？

丢失消息的地方

1. 生产者到 MQ 因网络等问题，丢失消息
2. MQ 挂了，内存中的消息丢失
3. 消费者收到消息，但在处理时消息挂了，但 MQ 认为已经消费完成，但实际上消息丢了



以上面的三个过程分别解决

1. 

CASE1: 开启事务，try catch 同步机制，效率低

CASE2: 类 Rabbit 的回调机制，可以保证的是消息吞吐量比较高



2. 

CASE1: RabbitMQ 持久化元数据至磁盘，仍然可能持久化途中挂了，导致消息丢失（概率较低）

3. 

CASE1: 像AUTOCOMMIT会导致消息丢失，关闭 AUTOACK，手动 ACK



## Q: 如何保证消息的顺序性

不论是 MQ 还是线程，都会导致消息的顺序性错乱

可以使用多个内存队列来保证

![image-20190813160806355](../img/image-20190813160806355.png)

假设消息1，消息2，消息3 都是同一个业务，再假设有一个订单 id，则将 消息的订单 id hash 后分发到内存队列中，同一个业务的消息则会在一个队列中，且会保持顺序，此时再用单线程去处理也能保持消息的顺序性













